{
  "best_metric": 0.9524495005607605,
  "best_model_checkpoint": "experiments/checkpoint-300",
  "epoch": 0.7710843373493976,
  "eval_steps": 50,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 0.22206813097000122,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 2.1849,
      "step": 10
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37702032923698425,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 2.1421,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5658480525016785,
      "learning_rate": 8.999999999999999e-05,
      "loss": 1.994,
      "step": 30
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.45784175395965576,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.6749,
      "step": 40
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.19926653802394867,
      "learning_rate": 0.00015,
      "loss": 1.49,
      "step": 50
    },
    {
      "epoch": 0.13,
      "eval_loss": 1.442154884338379,
      "eval_runtime": 16.6872,
      "eval_samples_per_second": 11.985,
      "eval_steps_per_second": 1.498,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0612225532531738,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.4096,
      "step": 60
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2915000915527344,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.3788,
      "step": 70
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2029956579208374,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.3425,
      "step": 80
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1851952075958252,
      "learning_rate": 0.00027,
      "loss": 1.3212,
      "step": 90
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3164965510368347,
      "learning_rate": 0.0003,
      "loss": 1.2704,
      "step": 100
    },
    {
      "epoch": 0.26,
      "eval_loss": 1.2845687866210938,
      "eval_runtime": 16.6307,
      "eval_samples_per_second": 12.026,
      "eval_steps_per_second": 1.503,
      "step": 100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2799418270587921,
      "learning_rate": 0.000285,
      "loss": 1.2447,
      "step": 110
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.29107099771499634,
      "learning_rate": 0.00027,
      "loss": 1.2302,
      "step": 120
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2571757733821869,
      "learning_rate": 0.00025499999999999996,
      "loss": 1.1837,
      "step": 130
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.31148386001586914,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.1622,
      "step": 140
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3941388726234436,
      "learning_rate": 0.000225,
      "loss": 1.1476,
      "step": 150
    },
    {
      "epoch": 0.39,
      "eval_loss": 1.1482816934585571,
      "eval_runtime": 16.4648,
      "eval_samples_per_second": 12.147,
      "eval_steps_per_second": 1.518,
      "step": 150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.47527235746383667,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.1117,
      "step": 160
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5020874738693237,
      "learning_rate": 0.000195,
      "loss": 1.0798,
      "step": 170
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5180836319923401,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.1,
      "step": 180
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37183234095573425,
      "learning_rate": 0.000165,
      "loss": 1.0699,
      "step": 190
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.43934935331344604,
      "learning_rate": 0.00015,
      "loss": 1.0649,
      "step": 200
    },
    {
      "epoch": 0.51,
      "eval_loss": 1.0429024696350098,
      "eval_runtime": 16.7124,
      "eval_samples_per_second": 11.967,
      "eval_steps_per_second": 1.496,
      "step": 200
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5888434648513794,
      "learning_rate": 0.000135,
      "loss": 1.0303,
      "step": 210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4427335858345032,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.0107,
      "step": 220
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5892992615699768,
      "learning_rate": 0.00010499999999999999,
      "loss": 1.0147,
      "step": 230
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.45759546756744385,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.9936,
      "step": 240
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.609738826751709,
      "learning_rate": 7.5e-05,
      "loss": 0.9905,
      "step": 250
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.9792239665985107,
      "eval_runtime": 16.5772,
      "eval_samples_per_second": 12.065,
      "eval_steps_per_second": 1.508,
      "step": 250
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4619521498680115,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 0.9963,
      "step": 260
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.44652801752090454,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.9786,
      "step": 270
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.39960479736328125,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.9718,
      "step": 280
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.44882625341415405,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 0.9676,
      "step": 290
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.42309850454330444,
      "learning_rate": 0.0,
      "loss": 0.9646,
      "step": 300
    },
    {
      "epoch": 0.77,
      "eval_loss": 0.9524495005607605,
      "eval_runtime": 16.6374,
      "eval_samples_per_second": 12.021,
      "eval_steps_per_second": 1.503,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "total_flos": 5.992109808274637e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
